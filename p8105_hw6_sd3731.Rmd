---
title: "p8105_hw6_sd3731"
author: "Susie Dong"
date: "2023-12-02"
output: html_document
---

```{r, include=FALSE}
library(tidyverse)
library(readxl)
library(modelr)
library(mgcv)
knitr::opts_chunk$set(
	warning = FALSE,
	message = FALSE,
	fig.width = 8, 
	fig.height = 6)

theme_set(theme_minimal())
```


## Problem 1

```{r homicide_data cleaning}
omit_location = c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL")
omit_race = c("White", "Black")

homicide = read_csv("data/homicide-data.csv")
homicide = homicide |>
  mutate(city_state = str_c(city, state, sep = ", "),
         resolved = as.numeric(disposition == "Closed by arrest"),
         victim_age = as.numeric(victim_age)) |>
  filter(!city_state %in% omit_location & 
         victim_race %in% omit_race &
         victim_sex != "Unknown") |>
  drop_na(victim_age) |>
  select(resolved, victim_age, victim_race, victim_sex, city_state)

```


```{r fit glm}
logit_model = homicide |> 
  filter(city_state == "Baltimore, MD") |>
  glm(resolved ~ victim_age + victim_sex + victim_race, data = _, family = "binomial")
broom::tidy(logit_model, conf.int = T) |>
  mutate(OR = exp(estimate),
         OR.conf.low = exp(conf.low),
         OR.conf.high = exp(conf.high)) |>
  filter(str_detect(term, "sex")) |>
  select(term, OR, OR.conf.low, OR.conf.high) |>
  knitr::kable(digits = 3)
  
```


```{r glm for each city}
tidy_stats = function(city, df){
  df |> 
    filter(city_state == city) |>
    glm(resolved ~ victim_age + victim_sex + victim_race, data = _, family = "binomial") |>
    broom::tidy(conf.int = T) |>
    mutate(OR = exp(estimate),
           OR.conf.low = exp(conf.low),
           OR.conf.high = exp(conf.high)) |>
    filter(str_detect(term, "sex")) |>
    select(term, OR, OR.conf.low, OR.conf.high)
}

cities = homicide |> pull(city_state) |> unique()
test_on_city = tibble(
  city = cities,
  hypo = map(cities, tidy_stats, df = homicide)
) |> unnest(hypo) |>
  select(-term)
test_on_city |>
  knitr::kable(digits = 3)

```


```{r plot}
test_on_city |>
  mutate(city = fct_reorder(city, OR)) |>
  ggplot(aes(x = city, y = OR, color = city)) +
  geom_point() +
  geom_errorbar(aes(ymin = OR.conf.low, ymax = OR.conf.high)) +
  theme_bw() +
  labs(x = "city", y = "OR", title = "OR of sex") +
  theme(plot.title = element_text(hjust = 0.5), axis.title.x=element_blank(),
        axis.text.x=element_blank(), axis.ticks.x=element_blank())

```


Summary:
* The majority of cities show odds ratios (OR) less than 1, indicating that, after adjusting for victim age and race, crimes involving male victims are less likely to be resolved compared to those with female victims.
* Albuquerque, NM stands out with a notably higher OR, suggesting the opposite trend in this city: crimes with female victims have lower odds of resolution.


## Problem 2

```{r weather_data import}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2022-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())
```


```{r bootstrap}
bootstrap_results <-
  weather_df |> 
  modelr::bootstrap(n = 5000) |> 
  mutate(
    models = map(strap, \(df) lm(tmax ~ tmin + prcp, data = df)),
    summary = map(models, broom::glance),
    results = map(models, broom::tidy)) |> 
  select(-models) |> 
  unnest(summary, results) |> 
  select(id = .id, r.squared, term, estimate) |> 
  pivot_wider(
    names_from = term,
    values_from = estimate) |> 
  mutate(
    log_b1b2 = log(tmin * prcp)
  ) |> 
  select(id, r.squared, log_b1b2)
```


```{r conf for r2}
bootstrap_results |> 
  ggplot(aes(x = r.squared)) + geom_density() + 
  labs(title = "Distribution of estimated r square")

LB_r = bootstrap_results |> pull(r.squared) |>  quantile(0.025)
UB_r =bootstrap_results |> pull(r.squared) |>  quantile(0.975)

c(LB_r, UB_r)|> 
  knitr::kable(digits = 3)
```

Comments: The distribution of $\hat{r^2}$ shows a mild skewness towards the left, spanning between 0.86 and 0.96, with its most frequent value approximately at 0.92. The lower and upper bounds of its 95% confidence interval, marked by the 2.5% and 97.5% quantiles, are `r LB_r |> round(3)` and `r UB_r |> round(3)`, respectively. This interval can be denoted as (`r LB_r |> round(3)`, `r UB_r |> round(3)`).


```{r conf for logb1b2}
bootstrap_results |> 
  filter(log_b1b2 != "NaN") |> 
  ggplot(aes(x = log_b1b2)) + geom_density() +
  labs(title = "Distribution of estimated log(beta1 * beta2)")

LB_b = bootstrap_results |> filter(log_b1b2 != "NaN") |> pull(log_b1b2) |>  quantile(0.025)
UB_b =bootstrap_results |> filter(log_b1b2 != "NaN") |> pull(log_b1b2) |>  quantile(0.975)

c(LB_b, UB_b)|> 
  knitr::kable(digits = 3)
```


The distribution of $log(\hat{\beta_1} * \hat{\beta_2})$ exhibits a pronounced left-skew, stretching from -12 to -4, and predominantly centers around -5.5. The distribution's 2.5% and 97.5% quantiles are `r LB_b |> round(3)` and `r UB_b |> round(3)`, respectively, defining a 95% confidence interval represented as (`r LB_b |> round(3)`, `r UB_b |> round(3)`).


## Problem 3

```{r data import}
bw_df <-
  read_csv("data/birthweight.csv", na = c("", "."))
```


```{r data cleaning}
bw_df_clean <-
  bw_df |> 
  mutate(
    babysex = as.factor(babysex),
    frace = as.factor(frace),
    malform = as.factor(malform),
    mrace = as.factor(mrace)
  ) |> 
  select(bwt, everything())
```


```{r fit the model}
hypo_model = lm(bwt ~ bhead + blength + delwt + gaweeks + malform + smoken , data = bw_df_clean)
summary(hypo_model) |> broom::tidy()
# because malform has p-value > 0.05, we remove it from the model
my_model = lm(bwt ~ bhead + blength + delwt + gaweeks + smoken , data = bw_df_clean)
summary(my_model) |> broom::tidy()
```

Comments:
Initially, I formulated a primary model to investigate factors affecting children's birth weights, incorporating six predictors: `bhead`, `blength`, `delwt`, `gaweeks`, `malform`, and `smoken`. Upon conducting backward elimination, I found that the `malform` variable had the highest p-value of 0.61, exceeding the alpha threshold of 0.05. Consequently, I removed `malform` and refitted the model with the remaining five predictors. In this revised model, all coefficients exhibited p-values below 0.05. Therefore, the final model retained `bhead`, `blength`, `delwt`, `gaweeks`, and `smoken` as significant predictors.


```{r residuals - fitted values}
bw_df_clean |> 
  add_predictions(my_model) |> 
  add_residuals(my_model) |> 
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = 0.5) +
  geom_smooth() +
  labs(title = "Model residuals against fitted values")
```

```{r cross validation}
# cv
model_1 = lm(bwt ~ blength + gaweeks, data = bw_df_clean)
model_2 = lm(bwt ~ bhead + blength + babysex + 
               bhead * blength + bhead * babysex + blength * babysex, data = bw_df_clean)
cv_df <-
  crossv_mc(bw_df_clean, 100) 

cv_df <-  
  cv_df |> 
  mutate(
    my_model  = map(train, \(df) lm(bwt ~ bhead + blength + delwt + gaweeks + smoken, 
                                    data = df)),
    model_1  = map(train, \(df) lm(bwt ~ blength + gaweeks, data = df)),
    model_2  = map(train, \(df) lm(bwt ~ bhead + blength + babysex + 
               bhead * blength + bhead * babysex + blength * babysex, data = df))) |> 
  mutate(
    rmse_my_model = map2_dbl(my_model, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_model_1 = map2_dbl(model_1, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_model_2 = map2_dbl(model_2, test, \(mod, df) rmse(model = mod, data = df)))
```


```{r violin plot}
cv_df |> 
  select(starts_with("rmse")) |> 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") |> 
  mutate(model = fct_inorder(model)) |> 
  ggplot(aes(x = model, y = rmse, fill = model)) + geom_violin()
```

Comments:
Based on the violin plot, my_model exhibits the lowest rmse value, while model_2 has a rmse that is marginally higher than that of my_model. In contrast, Model_1 displays a significantly higher rmse in comparison to the other models, suggesting that its predictions might be less precise than those made by the other two models.






